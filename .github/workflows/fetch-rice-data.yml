name: Fetch Daily Rice Data

on:
  schedule:
    # Run daily at 8am UTC (midnight PST)
    - cron: '0 8 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  fetch-and-sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4

      - name: Fetch latest rice data
        id: fetch
        run: |
          python - <<'EOF'
          import requests
          from bs4 import BeautifulSoup
          from datetime import datetime, timedelta
          import json
          import sys

          STATS_URL = 'https://engine.freerice.com/stats/rice/daily.html'

          def fetch_daily_stats():
              try:
                  headers = {
                      'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                  }
                  response = requests.get(STATS_URL, headers=headers, timeout=10)
                  response.raise_for_status()
                  return response.text
              except Exception as e:
                  print(f"Error fetching stats: {e}")
                  return None

          def parse_stats_table(html):
              soup = BeautifulSoup(html, 'html.parser')
              table = soup.find('table')

              if not table:
                  return []

              data = []
              rows = table.find_all('tr')[1:]  # Skip header

              for row in rows:
                  cols = row.find_all('td')
                  if len(cols) >= 2:
                      date_str = cols[0].text.strip()
                      grains_str = cols[1].text.strip()

                      try:
                          date = datetime.strptime(date_str, '%Y-%m-%d').date()
                          grains = int(grains_str)
                          data.append({'date': str(date), 'grains': grains})
                      except ValueError:
                          pass

              return data

          # Fetch data
          html = fetch_daily_stats()
          if not html:
              print("Failed to fetch data")
              sys.exit(1)

          data = parse_stats_table(html)
          if not data:
              print("No data parsed")
              sys.exit(1)

          # Get yesterday's date
          yesterday = (datetime.now() - timedelta(days=1)).date()

          # Find yesterday's data
          yesterday_data = None
          for entry in data:
              if entry['date'] == str(yesterday):
                  yesterday_data = entry
                  break

          if not yesterday_data:
              print(f"No data found for {yesterday}")
              sys.exit(1)

          # Output for next step
          print(f"DATE={yesterday_data['date']}")
          print(f"GRAINS={yesterday_data['grains']}")

          # Also save to GITHUB_OUTPUT
          import os
          if 'GITHUB_OUTPUT' in os.environ:
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"date={yesterday_data['date']}\n")
                  f.write(f"grains={yesterday_data['grains']}\n")
          EOF

      - name: Send data to Fly.io app
        env:
          API_TOKEN: ${{ secrets.API_TOKEN }}
          FLY_APP_URL: https://freerice-tracker.fly.dev
        run: |
          curl -X POST "$FLY_APP_URL/api/import-day" \
            -H "Content-Type: application/json" \
            -H "X-API-Token: $API_TOKEN" \
            -d "{\"date\": \"${{ steps.fetch.outputs.date }}\", \"grains\": ${{ steps.fetch.outputs.grains }}}" \
            -f || echo "Failed to send data to Fly.io"
